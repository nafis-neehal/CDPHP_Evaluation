{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an Notebook which can evalute multiple files.  It implements a number of features:\n",
    "\n",
    "- TopK\n",
    "- Removing recent referrals\n",
    "- Thresholding \n",
    "- Tables and visualization\n",
    "- Config files for standardized processes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#ignore warnings.\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "#imports\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import importlib\n",
    "import yaml, json\n",
    "from pathlib import Path\n",
    "\n",
    "#path append\n",
    "sys.path.append(os.path.join(Path.cwd(), 'modules'))\n",
    "import Evaluate, Helper, Present, Score, Synthetic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Imports</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File configuration\n",
    "<p> Just edit the configuration file path/address. prediction_files contain configs for different prediction files. config_file contains other configs for referral, visualization, experiment etc. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple prediction file load still works, just loaded a single file because too many things are being displayed otherwise.\n",
    "config_file = 'config/config.yaml'\n",
    "prediction_config_files = ['config/predictions/pred1.yaml', 'config/predictions/pred2.yaml']\n",
    "generate_data=False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration and Referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transferred referral data loading inside the c_p for loop below, because referral_data is being changed for date format adjustment. \n",
    "As referral_data.copy() is not allowed for memory issues. The overhead shouldn't be much.\n",
    "'''\n",
    "\n",
    "#Load Configuration\n",
    "c_r, c_e, c_gen, c_aws, c_visual, predictions=Helper.load_configuration(config_file, prediction_config_files)\n",
    "\n",
    "#Generate Data (if required)\n",
    "if generate_data:\n",
    "    Synthetic.generate_synthetic_event_data(c_gen)\n",
    "    Synthetic.generate_synthetic_prediction_data(c_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precheck Prediction and Referral Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns from dataframe (referral/prediction): ['PERSON_ID', 'MYR']\n",
      "Columns from config(c_r/c_p): ['PERSON_ID', 'MYR']\n",
      "Referral Columns match\n",
      "Columns from dataframe (referral/prediction): ['PERSON_ID', 'MYR', 'lin_reg', 'rand_forest', 'xg_boost', 'sgmm']\n",
      "Columns from config(c_r/c_p): ['PERSON_ID', 'MYR']\n",
      "Columns from dataframe (referral/prediction): ['PERSON_ID', 'MYR', 'lin_reg', 'rand_forest', 'xg_boost', 'sgmm']\n",
      "Columns from config(c_r/c_p): ['PERSON_ID', 'MYR']\n",
      "Prediction Columns match\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#assert for column matches between config and data files\n",
    "#check if columns mentioned under c_r['columns'] and c_p['columns'] are available in referral and prediction data\n",
    "#this is the only check possible without loading the whole data into the memory\n",
    "\n",
    "referral_file = c_r['dir'] + c_r['file']\n",
    "with open(referral_file, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    i = next(reader)\n",
    "    assert Helper.column_exists(i, c_r['columns']), \"Column mismatch for referral\"\n",
    "print(\"Referral Columns match\")\n",
    "\n",
    "for c_p in predictions:\n",
    "    file = c_p['dir'] + c_p['file']\n",
    "    with open(file, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = next(reader)\n",
    "        assert Helper.column_exists(i, c_p['columns']), \"Column mismatch for prediction\"\n",
    "print(\"Prediction Columns match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty results from previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete results from previous run\n",
    "result_file = c_e['dir'] + c_e['file']\n",
    "\n",
    "if os.path.exists(result_file):\n",
    "  os.remove(result_file)\n",
    "else:\n",
    "  print(\"The result directory is currently empty. Generating result file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Models\n",
    "For each configuration file provided it will evaluate the models. It will save all the results for all prediction files in the current run in the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load referrals\n",
    "referrals=Helper.read_file(directory=c_r['dir'],file=c_r['file'],file_format=c_r['file_format'],aws=c_r['aws'],bucket= c_r['bucket'])\n",
    "\n",
    "#run again for all prediction files\n",
    "for c_p in predictions:    \n",
    "    \n",
    "    #load prediction\n",
    "    prediction=Helper.read_file(directory=c_p['dir'],file=c_p['file'],file_format=c_p['file_format'],aws=c_p['aws'],bucket= c_p['bucket'])\n",
    "    \n",
    "    #eval date extract\n",
    "    date_list = Helper.eval_date_extract(c_p, prediction)\n",
    "    \n",
    "    #run evaluation for all eval dates and process and save them in CSV\n",
    "    for eval_date in date_list:\n",
    "        c_e['eval_date'] = eval_date\n",
    "        all_model_evaluations = Evaluate.evaluate(c_p, c_e, c_r, referrals, prediction)\n",
    "        #Present.present_evaluation(c_p, c_r, c_e, c_visual, eval_date, all_model_evaluations)\n",
    "        Present.process_evaluation_data(c_p, c_r, c_e, c_visual, eval_date, all_model_evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy_@k=50</th>\n",
       "      <th>accuracy_@p&gt;=0.5</th>\n",
       "      <th>precision_@k=50</th>\n",
       "      <th>precision_@p&gt;=0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Prediction Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">lin_reg</th>\n",
       "      <th>predictions.csv</th>\n",
       "      <td>0.892968</td>\n",
       "      <td>0.495665</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.008205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions2.csv</th>\n",
       "      <td>0.892968</td>\n",
       "      <td>0.495665</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.008205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rand_forest</th>\n",
       "      <th>predictions.csv</th>\n",
       "      <td>0.891957</td>\n",
       "      <td>0.503481</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.006002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions2.csv</th>\n",
       "      <td>0.891957</td>\n",
       "      <td>0.503481</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.006002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sgmm</th>\n",
       "      <th>predictions.csv</th>\n",
       "      <td>0.892628</td>\n",
       "      <td>0.504056</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions2.csv</th>\n",
       "      <td>0.892628</td>\n",
       "      <td>0.504056</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">xg_boost</th>\n",
       "      <th>predictions.csv</th>\n",
       "      <td>0.892799</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.009045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions2.csv</th>\n",
       "      <td>0.892799</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.009045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy_@k=50  accuracy_@p>=0.5  \\\n",
       "Model       Prediction Source                                     \n",
       "lin_reg     predictions.csv          0.892968          0.495665   \n",
       "            predictions2.csv         0.892968          0.495665   \n",
       "rand_forest predictions.csv          0.891957          0.503481   \n",
       "            predictions2.csv         0.891957          0.503481   \n",
       "sgmm        predictions.csv          0.892628          0.504056   \n",
       "            predictions2.csv         0.892628          0.504056   \n",
       "xg_boost    predictions.csv          0.892799          0.497701   \n",
       "            predictions2.csv         0.892799          0.497701   \n",
       "\n",
       "                               precision_@k=50  precision_@p>=0.5  \n",
       "Model       Prediction Source                                      \n",
       "lin_reg     predictions.csv           0.009167           0.008205  \n",
       "            predictions2.csv          0.009167           0.008205  \n",
       "rand_forest predictions.csv           0.004167           0.006002  \n",
       "            predictions2.csv          0.004167           0.006002  \n",
       "sgmm        predictions.csv           0.007500           0.008370  \n",
       "            predictions2.csv          0.007500           0.008370  \n",
       "xg_boost    predictions.csv           0.008333           0.009045  \n",
       "            predictions2.csv          0.008333           0.009045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this section will present tables, comparison plots and will save them\n",
    "Present.present_evaluation(c_e, c_visual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
